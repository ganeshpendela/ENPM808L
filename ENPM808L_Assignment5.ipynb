{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mywpUk87kRfM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(r'/IrisNew.csv')\n",
        "df = pd.DataFrame(data, columns=[\"Sepal Length\",\"Sepal Width\",\"Petal Length\",\"Petal Width\",\"Class\"])\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T8CLV4Dm3bW",
        "outputId": "e56c0266-9418-4e55-df68-b43657aa98c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Sepal Length  Sepal Width  Petal Length  Petal Width      Class\n",
            "0             4.3          3.0           1.1          0.1     setosa\n",
            "1             4.4          2.9           1.4          0.2     setosa\n",
            "2             4.4          3.0           1.3          0.2     setosa\n",
            "3             4.4          3.2           1.3          0.2     setosa\n",
            "4             4.5          2.3           1.3          0.3     setosa\n",
            "..            ...          ...           ...          ...        ...\n",
            "145           7.7          2.6           6.9          2.3  virginica\n",
            "146           7.7          2.8           6.7          2.0  virginica\n",
            "147           7.7          3.0           6.1          2.3  virginica\n",
            "148           7.7          3.8           6.7          2.2  virginica\n",
            "149           7.9          3.8           6.4          2.0  virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split the data into training and testing\n",
        "X = df.values[:,0:4] # first 4 columns are independent variables\n",
        "Y = df.values[:,4] # last column is dependent variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3,random_state=100)\n",
        "#test size = 70% training and 30 percent testing\n"
      ],
      "metadata": {
        "id": "Lyis_B8am4sj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "kFT9pkl3m4vZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3  # You can choose the number of neighbors (k) based on cross-validation.\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "l2hyxEv4m4yY",
        "outputId": "d823db3f-e46c-4c3d-f30c-88d0c50e0f80"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YrfTB_jnMQp",
        "outputId": "22b8e086-c2d4-499a-fecd-9995fe9d5680"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9777777777777777\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        13\n",
            "  versicolor       0.94      1.00      0.97        15\n",
            "   virginica       1.00      0.94      0.97        17\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.98      0.98        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n",
            "Confusion Matrix:\n",
            "[[13  0  0]\n",
            " [ 0 15  0]\n",
            " [ 0  1 16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Decision Tree model, criterion = Entropy\n",
        "dt_model = DecisionTreeClassifier(criterion = \"entropy\",random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "# Train the Decision Tree model, criterion = Gini Index\n",
        "dt_model1 = DecisionTreeClassifier(criterion = \"gini\",random_state=42)\n",
        "dt_model1.fit(X_train, y_train)\n",
        "y_pred_dt1 = dt_model1.predict(X_test)\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "# Train the KNN model\n",
        "k = 3\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_model.fit(X_train, y_train)\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "\n",
        "# Evaluate and compare the models\n",
        "models = [(\"Decision Tree with criterion as entropy\", y_pred_dt), (\"Decision Tree with criterion as gini\", y_pred_dt1),\n",
        " (\"Logistic Regression\", y_pred_lr), (\"K-Nearest Neighbors\", y_pred_knn)]\n",
        "\n",
        "for model_name, y_pred in models:\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'{model_name} Accuracy: {accuracy}')\n",
        "\n",
        "    print(f\"{model_name} Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(f\"{model_name} Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sqt_7S2UoXnB",
        "outputId": "bdc07616-794b-47e6-ca54-32aebbffa9b9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree with criterion as entropy Accuracy: 0.9555555555555556\n",
            "Decision Tree with criterion as entropy Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        13\n",
            "  versicolor       0.93      0.93      0.93        15\n",
            "   virginica       0.94      0.94      0.94        17\n",
            "\n",
            "    accuracy                           0.96        45\n",
            "   macro avg       0.96      0.96      0.96        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n",
            "Decision Tree with criterion as entropy Confusion Matrix:\n",
            "[[13  0  0]\n",
            " [ 0 14  1]\n",
            " [ 0  1 16]]\n",
            "Decision Tree with criterion as gini Accuracy: 0.9555555555555556\n",
            "Decision Tree with criterion as gini Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        13\n",
            "  versicolor       0.93      0.93      0.93        15\n",
            "   virginica       0.94      0.94      0.94        17\n",
            "\n",
            "    accuracy                           0.96        45\n",
            "   macro avg       0.96      0.96      0.96        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n",
            "Decision Tree with criterion as gini Confusion Matrix:\n",
            "[[13  0  0]\n",
            " [ 0 14  1]\n",
            " [ 0  1 16]]\n",
            "Logistic Regression Accuracy: 0.9555555555555556\n",
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        13\n",
            "  versicolor       0.93      0.93      0.93        15\n",
            "   virginica       0.94      0.94      0.94        17\n",
            "\n",
            "    accuracy                           0.96        45\n",
            "   macro avg       0.96      0.96      0.96        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n",
            "Logistic Regression Confusion Matrix:\n",
            "[[13  0  0]\n",
            " [ 0 14  1]\n",
            " [ 0  1 16]]\n",
            "K-Nearest Neighbors Accuracy: 0.9777777777777777\n",
            "K-Nearest Neighbors Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        13\n",
            "  versicolor       0.94      1.00      0.97        15\n",
            "   virginica       1.00      0.94      0.97        17\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.98      0.98        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n",
            "K-Nearest Neighbors Confusion Matrix:\n",
            "[[13  0  0]\n",
            " [ 0 15  0]\n",
            " [ 0  1 16]]\n"
          ]
        }
      ]
    }
  ]
}