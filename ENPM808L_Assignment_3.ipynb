{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression for Iris dataset"
      ],
      "metadata": {
        "id": "F0ZDp3I1_7W9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "0s6r_oQmXRtN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(r'/IrisNew.csv')\n",
        "print(data)\n",
        "df = pd.DataFrame(data, columns=[\"Sepal Length\",\"Sepal Width\",\"Petal Length\",\"Petal Width\",\"Class\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD-RfwgfaTUa",
        "outputId": "f16d7c1e-8ef2-4882-dcbd-79042bcda6ca"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Sepal Length  Sepal Width  Petal Length  Petal Width      Class\n",
            "0             4.3          3.0           1.1          0.1     setosa\n",
            "1             4.4          2.9           1.4          0.2     setosa\n",
            "2             4.4          3.0           1.3          0.2     setosa\n",
            "3             4.4          3.2           1.3          0.2     setosa\n",
            "4             4.5          2.3           1.3          0.3     setosa\n",
            "..            ...          ...           ...          ...        ...\n",
            "145           7.7          2.6           6.9          2.3  virginica\n",
            "146           7.7          2.8           6.7          2.0  virginica\n",
            "147           7.7          3.0           6.1          2.3  virginica\n",
            "148           7.7          3.8           6.7          2.2  virginica\n",
            "149           7.9          3.8           6.4          2.0  virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.values[:,0:4] # first 4 columns are independent variables\n",
        "Y = df.values[:,4] # last column is dependent variable\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3,random_state=100)\n",
        "#test size = 70% training and 30 percent testing\n",
        "\n"
      ],
      "metadata": {
        "id": "5Un_pULVc-fA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create and train the logistic regression model\n",
        "logistic_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "logistic_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logistic_reg.predict(X_test)\n",
        "print(y_pred)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", confusion)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBGqmifvixpQ",
        "outputId": "6edbe981-820e-47bb-ffc7-7df480aa7416"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['virginica' 'setosa' 'virginica' 'setosa' 'virginica' 'virginica'\n",
            " 'versicolor' 'setosa' 'virginica' 'setosa' 'setosa' 'versicolor' 'setosa'\n",
            " 'setosa' 'virginica' 'versicolor' 'versicolor' 'virginica' 'virginica'\n",
            " 'virginica' 'versicolor' 'setosa' 'virginica' 'setosa' 'versicolor'\n",
            " 'virginica' 'versicolor' 'setosa' 'versicolor' 'versicolor' 'virginica'\n",
            " 'versicolor' 'virginica' 'setosa' 'versicolor' 'setosa' 'versicolor'\n",
            " 'versicolor' 'virginica' 'virginica' 'versicolor' 'versicolor'\n",
            " 'virginica' 'virginica' 'setosa']\n",
            "Accuracy: 0.9555555555555556\n",
            "Confusion Matrix:\n",
            " [[13  0  0]\n",
            " [ 0 14  1]\n",
            " [ 0  1 16]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        13\n",
            "  versicolor       0.93      0.93      0.93        15\n",
            "   virginica       0.94      0.94      0.94        17\n",
            "\n",
            "    accuracy                           0.96        45\n",
            "   macro avg       0.96      0.96      0.96        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ranking of the results of the logistic regression model using the modelâ€™s predict_proba method\n",
        "\n",
        "y_probabilities = logistic_reg.predict_proba(X_test)\n",
        "\n",
        "# Assuming y_probabilities is an array of shape (n_samples, n_classes), you can rank the results\n",
        "# based on the predicted probabilities for each class.\n",
        "ranking = np.argsort(-y_probabilities, axis=1)  # Sort in descending order\n",
        "print(\"Ranking of Results (Top 3 classes for each sample):\\n\", ranking[:, :3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy0DkP_f7dJd",
        "outputId": "004d6e1c-22ed-42ee-de01-30e3461fa62c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking of Results (Top 3 classes for each sample):\n",
            " [[2 1 0]\n",
            " [0 1 2]\n",
            " [2 1 0]\n",
            " [0 1 2]\n",
            " [2 1 0]\n",
            " [2 1 0]\n",
            " [1 0 2]\n",
            " [0 1 2]\n",
            " [2 1 0]\n",
            " [0 1 2]\n",
            " [0 1 2]\n",
            " [1 2 0]\n",
            " [0 1 2]\n",
            " [0 1 2]\n",
            " [2 1 0]\n",
            " [1 2 0]\n",
            " [1 0 2]\n",
            " [2 1 0]\n",
            " [2 1 0]\n",
            " [2 1 0]\n",
            " [1 2 0]\n",
            " [0 1 2]\n",
            " [2 1 0]\n",
            " [0 1 2]\n",
            " [1 2 0]\n",
            " [2 1 0]\n",
            " [1 0 2]\n",
            " [0 1 2]\n",
            " [1 2 0]\n",
            " [1 2 0]\n",
            " [2 1 0]\n",
            " [1 2 0]\n",
            " [2 1 0]\n",
            " [0 1 2]\n",
            " [1 0 2]\n",
            " [0 1 2]\n",
            " [1 2 0]\n",
            " [1 2 0]\n",
            " [2 1 0]\n",
            " [2 1 0]\n",
            " [1 2 0]\n",
            " [1 2 0]\n",
            " [2 1 0]\n",
            " [2 1 0]\n",
            " [0 1 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = np.array([[5.8, 2.8, 5.1, 2.4], [6.0, 2.2, 4.0, 1.0]])\n",
        "\n",
        "# Standardize the new data using the same scaler as before\n",
        "new_data_standardized = scaler.transform(new_data)\n",
        "\n",
        "# Predict probabilities for each class\n",
        "predicted_probabilities = logistic_reg.predict_proba(new_data_standardized)\n",
        "\n",
        "# Assuming you have classes names for reference, e.g., [\"Class 1\", \"Class 2\", \"Class 3\", \"Class 4\", \"Class 5\"]\n",
        "class_names = [\"setosa\", \"versicolor\", \"virginica\"]\n",
        "\n",
        "# Rank the classes based on predicted probabilities for each new data record\n",
        "rankings = np.argsort(-predicted_probabilities, axis=1)\n",
        "\n",
        "# Print the rankings for each new data record\n",
        "for i, new_record in enumerate(new_data):\n",
        "    print(f\"Ranking for New Record {i + 1}:\")\n",
        "    for j, rank in enumerate(rankings[i]):\n",
        "        class_name = class_names[rank]\n",
        "        probability = predicted_probabilities[i][rank]\n",
        "        print(f\"Rank {j + 1}: {class_name} (Probability: {probability:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-owvjjPRFp3N",
        "outputId": "8e53b126-3e76-44db-f651-796d3f2983ac"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking for New Record 1:\n",
            "Rank 1: virginica (Probability: 0.9621)\n",
            "Rank 2: versicolor (Probability: 0.0376)\n",
            "Rank 3: setosa (Probability: 0.0002)\n",
            "Ranking for New Record 2:\n",
            "Rank 1: versicolor (Probability: 0.9507)\n",
            "Rank 2: virginica (Probability: 0.0418)\n",
            "Rank 3: setosa (Probability: 0.0074)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression for Wiki Pass/Fail example data"
      ],
      "metadata": {
        "id": "iS9au1wfAUEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Input data (Hours of study)\n",
        "X = np.array([0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 1.75, 2.00, 2.25, 2.50, 2.75, 3.00, 3.25, 3.50, 4.00, 4.25, 4.50, 4.75, 5.00, 5.50]).reshape(-1, 1)\n",
        "\n",
        "# Target data (Pass or Fail, where 1 represents Pass and 0 represents Fail)\n",
        "y = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the logistic regression model\n",
        "logistic_reg = LogisticRegression()\n",
        "logistic_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logistic_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj8ZDozH6hxA",
        "outputId": "5d85f2e5-4ee0-4df0-eff8-8dee41b92679"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 1 0]\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the estimated probability of passing the exam for several values of hours studying\n",
        "study_hours = np.array([1, 2,2.7, 3, 4, 5]).reshape(-1, 1)\n",
        "probabilities = logistic_reg.predict_proba(study_hours)[:, 1]\n",
        "for hours, probability in zip(study_hours, probabilities):\n",
        "    print(f\"Study Hours: {hours[0]}, Probability of Passing: {probability:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rYYkR_-GRdK",
        "outputId": "10cb9482-9175-47af-85d6-80f777a4a56f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study Hours: 1.0, Probability of Passing: 0.1531\n",
            "Study Hours: 2.0, Probability of Passing: 0.3214\n",
            "Study Hours: 2.7, Probability of Passing: 0.4817\n",
            "Study Hours: 3.0, Probability of Passing: 0.5537\n",
            "Study Hours: 4.0, Probability of Passing: 0.7647\n",
            "Study Hours: 5.0, Probability of Passing: 0.8949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model evaluation"
      ],
      "metadata": {
        "id": "BKCuEt7SBAsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Input data (Hours of study)\n",
        "X = np.array([0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 1.75, 2.00, 2.25, 2.50, 2.75, 3.00, 3.25, 3.50, 4.00, 4.25, 4.50, 4.75, 5.00, 5.50])\n",
        "X = sm.add_constant(X)  # Add a constant term (intercept) to the input data\n",
        "\n",
        "# Target data (Pass or Fail, where 1 represents Pass and 0 represents Fail)\n",
        "y = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])\n",
        "\n",
        "# Fit logistic regression model using statsmodels\n",
        "logit_model = sm.Logit(y, X)\n",
        "result = logit_model.fit()\n",
        "\n",
        "# Get the summary of the logistic regression model, which includes standard errors, z-values, and p-values\n",
        "summary = result.summary()\n",
        "\n",
        "# Print the summary\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRTP7h4a81hc",
        "outputId": "cdec6e9d-da04-492a-fa5f-ad6d55eb202a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.401494\n",
            "         Iterations 7\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   No. Observations:                   20\n",
            "Model:                          Logit   Df Residuals:                       18\n",
            "Method:                           MLE   Df Model:                            1\n",
            "Date:                Thu, 21 Sep 2023   Pseudo R-squ.:                  0.4208\n",
            "Time:                        23:32:58   Log-Likelihood:                -8.0299\n",
            "converged:                       True   LL-Null:                       -13.863\n",
            "Covariance Type:            nonrobust   LLR p-value:                 0.0006365\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -4.0777      1.761     -2.316      0.021      -7.529      -0.626\n",
            "x1             1.5046      0.629      2.393      0.017       0.272       2.737\n",
            "==============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Input data (Hours of study)\n",
        "X = np.array([0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 1.75, 2.00, 2.25, 2.50, 2.75, 3.00, 3.25, 3.50, 4.00, 4.25, 4.50, 4.75, 5.00, 5.50]).reshape(-1, 1)\n",
        "\n",
        "# Target data (Pass or Fail, where 1 represents Pass and 0 represents Fail)\n",
        "y = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])\n",
        "\n",
        "# Create and train the logistic regression model\n",
        "logistic_reg = LogisticRegression()\n",
        "logistic_reg.fit(X, y)\n",
        "\n",
        "# Values of study hours for which you want to calculate probabilities\n",
        "study_hours = np.array([1, 2, 2.7,3, 4, 5]).reshape(-1, 1)\n",
        "\n",
        "# Calculate probabilities of passing for the given study hours\n",
        "probabilities = logistic_reg.predict_proba(study_hours)[:, 1]\n",
        "\n",
        "# Print the probabilities\n",
        "for hours, probability in zip(study_hours, probabilities):\n",
        "    print(f\"Study Hours: {hours[0]}, Probability of Passing: {probability:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8JHDvWXG3TY",
        "outputId": "7f7fab3a-727b-4b71-8eed-b074cd3c7b1b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study Hours: 1.0, Probability of Passing: 0.1202\n",
            "Study Hours: 2.0, Probability of Passing: 0.3010\n",
            "Study Hours: 2.7, Probability of Passing: 0.4904\n",
            "Study Hours: 3.0, Probability of Passing: 0.5760\n",
            "Study Hours: 4.0, Probability of Passing: 0.8108\n",
            "Study Hours: 5.0, Probability of Passing: 0.9311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Input data (Hours of study)\n",
        "X = np.array([0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 1.75, 2.00, 2.25, 2.50, 2.75, 3.00, 3.25, 3.50, 4.00, 4.25, 4.50, 4.75, 5.00, 5.50])\n",
        "X = sm.add_constant(X)  # Add a constant term (intercept) to the input data\n",
        "\n",
        "# Target data (Pass or Fail, where 1 represents Pass and 0 represents Fail)\n",
        "y = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])\n",
        "\n",
        "# Fit logistic regression model using statsmodels\n",
        "logit_model = sm.Logit(y, X)\n",
        "result = logit_model.fit()\n",
        "\n",
        "# Values of study hours for which you want to calculate probabilities\n",
        "study_hours = np.array([1, 2, 3, 4, 5])\n",
        "study_hours_with_const = sm.add_constant(study_hours)  # Add a constant term to the study hours\n",
        "\n",
        "# Calculate probabilities of passing for the given study hours\n",
        "probabilities = result.predict(study_hours_with_const)\n",
        "\n",
        "# Print the probabilities\n",
        "for hours, probability in zip(study_hours, probabilities):\n",
        "    print(f\"Study Hours: {hours}, Probability of Passing: {probability:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmp8LjvcHJOZ",
        "outputId": "530b3977-e974-4793-e257-e9225d3f5161"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.401494\n",
            "         Iterations 7\n",
            "Study Hours: 1, Probability of Passing: 0.0709\n",
            "Study Hours: 2, Probability of Passing: 0.2557\n",
            "Study Hours: 3, Probability of Passing: 0.6074\n",
            "Study Hours: 4, Probability of Passing: 0.8744\n",
            "Study Hours: 5, Probability of Passing: 0.9691\n"
          ]
        }
      ]
    }
  ]
}